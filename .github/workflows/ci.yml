name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      test_level:
        description: 'Test level to run (smoke, unit, integration, e2e, all)'
        required: false
        default: 'all'
        type: choice
        options:
          - smoke
          - unit
          - integration
          - e2e
          - all
      skip_cache:
        description: 'Skip cache for fresh CI run'
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: '18'
  POSTGRES_VERSION: '15'
  REDIS_VERSION: '7'
  # CI-specific optimizations
  CI: true
  FORCE_COLOR: 1
  # Test optimization flags
  VITEST_MIN_THREADS: 1
  VITEST_MAX_THREADS: 4
  # Cache configuration
  CACHE_VERSION: v1

jobs:
  # Job 0: Configuration Validation
  config-validation:
    name: CI Configuration Validation
    runs-on: ubuntu-latest
    
    outputs:
      config_valid: ${{ steps.validate.outputs.config_valid }}
      test_level: ${{ steps.test_config.outputs.test_level }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: ${{ github.event.inputs.skip_cache != 'true' && 'npm' || '' }}
          cache-dependency-path: package-lock.json

      - name: Validate CI configuration
        id: validate
        run: |
          echo "Validating CI/CD configuration..."
          
          # Check required files exist
          required_files=(
            "package.json"
            "vitest.config.ts"
            "playwright.config.ts"
            "run-tests.sh"
            "test/setup.ts"
          )
          
          for file in "${required_files[@]}"; do
            if [ ! -f "$file" ]; then
              echo "âŒ Required file missing: $file"
              exit 1
            fi
          done
          
          # Validate package.json scripts
          if ! jq -e '.scripts.test' package.json > /dev/null; then
            echo "âŒ Missing test script in package.json"
            exit 1
          fi
          
          echo "âœ… CI configuration validation passed"
          echo "config_valid=true" >> $GITHUB_OUTPUT

      - name: Determine test level
        id: test_config
        run: |
          TEST_LEVEL="${{ github.event.inputs.test_level || 'all' }}"
          echo "test_level=$TEST_LEVEL" >> $GITHUB_OUTPUT
          echo "Test level: $TEST_LEVEL"

      - name: Install dependencies for validation
        run: npm ci --prefer-offline --no-audit

      - name: Validate test configuration
        run: |
          echo "Validating test configuration files..."
          
          # Check vitest config
          if ! npx vitest --config vitest.config.ts --run --reporter=json --outputFile=/tmp/test-config-check.json --testNamePattern="non-existent-test" 2>/dev/null; then
            if [ $? -eq 1 ]; then
              echo "âœ… Vitest configuration is valid"
            else
              echo "âŒ Vitest configuration has errors"
              exit 1
            fi
          fi
          
          # Check playwright config
          npx playwright --version
          echo "âœ… Playwright configuration is valid"

  # Job 1: Code Quality & Security Scanning
  security-scan:
    name: Security & Dependency Scan
    runs-on: ubuntu-latest
    needs: config-validation
    if: needs.config-validation.outputs.config_valid == 'true'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Multi-layer enhanced caching strategy
      - name: Cache dependencies and build artifacts
        if: github.event.inputs.skip_cache != 'true'
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            node_modules
            ~/.cache/ms-playwright
            ~/.cache/vite
            .vite
            dist
            build
            coverage
          key: ${{ runner.os }}-deps-${{ env.CACHE_VERSION }}-${{ hashFiles('package-lock.json', 'vite.config.ts', 'vitest.config.ts') }}
          restore-keys: |
            ${{ runner.os }}-deps-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-deps-
            ${{ runner.os }}-node-
            
      - name: Cache TypeScript compilation
        if: github.event.inputs.skip_cache != 'true'
        uses: actions/cache@v4
        with:
          path: |
            .tsbuildinfo
            tsconfig.tsbuildinfo
            node_modules/.cache/typescript
          key: ${{ runner.os }}-typescript-${{ hashFiles('tsconfig.json', 'src/**/*.ts', 'server/**/*.ts') }}
          restore-keys: |
            ${{ runner.os }}-typescript-
            
      - name: Cache test artifacts
        if: github.event.inputs.skip_cache != 'true'
        uses: actions/cache@v4
        with:
          path: |
            test-results
            coverage
            .vitest
            playwright-report
            test-results
          key: ${{ runner.os }}-tests-${{ env.CACHE_VERSION }}-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-tests-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-tests-

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: ${{ github.event.inputs.skip_cache != 'true' && 'npm' || '' }}

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: Run npm audit
        run: npm audit --audit-level=moderate
        continue-on-error: true

      - name: Run dependency vulnerability scan
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: |
          npx audit-ci --config ./ci/audit-ci.json
        continue-on-error: true

      - name: Run ESLint security scan
        run: |
          npx eslint . --ext .ts,.tsx,.js,.jsx \
            --config ./ci/eslint-security.config.js \
            --format json \
            --output-file eslint-security-report.json
        continue-on-error: true

      - name: Upload security scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-scan-results
          path: |
            eslint-security-report.json
            npm-audit.json

  # Job 2: Unit Tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: [config-validation, security-scan]
    if: needs.config-validation.outputs.config_valid == 'true' && (needs.config-validation.outputs.test_level == 'all' || needs.config-validation.outputs.test_level == 'unit')
    
    strategy:
      matrix:
        test-group: [core, api, frontend, services]
      fail-fast: false
    
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}-alpine
        env:
          POSTGRES_DB: vonkfi_test
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:${{ env.REDIS_VERSION }}-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # Enhanced parallel job caching with test-group specific cache
      - name: Cache dependencies for parallel execution
        if: github.event.inputs.skip_cache != 'true'
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            node_modules
            .vite
            node_modules/.cache
          key: ${{ runner.os }}-parallel-${{ matrix.test-group }}-${{ env.CACHE_VERSION }}-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-parallel-${{ matrix.test-group }}-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-parallel-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-deps-${{ env.CACHE_VERSION }}-
            
      - name: Cache test group specific artifacts
        if: github.event.inputs.skip_cache != 'true'
        uses: actions/cache@v4
        with:
          path: |
            test-results
            coverage
            .vitest/cache
          key: ${{ runner.os }}-test-cache-${{ matrix.test-group }}-${{ hashFiles('test/**/*.ts', 'test/**/*.tsx') }}
          restore-keys: |
            ${{ runner.os }}-test-cache-${{ matrix.test-group }}-
            ${{ runner.os }}-test-cache-

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: ${{ github.event.inputs.skip_cache != 'true' && 'npm' || '' }}

      - name: Install dependencies
        run: npm ci --prefer-offline

      - name: Wait for PostgreSQL
        run: |
          timeout=300
          elapsed=0
          interval=5
          
          echo "ðŸ” Waiting for PostgreSQL to be ready..."
          while [ $elapsed -lt $timeout ]; do
            if pg_isready -h localhost -p 5432 -U test -d vonkfi_test; then
              echo "âœ… PostgreSQL is ready after ${elapsed}s"
              
              # Additional connection test
              if psql -h localhost -p 5432 -U test -d vonkfi_test -c "SELECT 1;" > /dev/null 2>&1; then
                echo "âœ… PostgreSQL connection test successful"
                break
              else
                echo "âš ï¸ PostgreSQL ready but connection failed, retrying..."
              fi
            fi
            
            echo "â³ Waiting for PostgreSQL... (${elapsed}s/${timeout}s)"
            sleep $interval
            elapsed=$((elapsed + interval))
          done
          
          if [ $elapsed -ge $timeout ]; then
            echo "âŒ PostgreSQL failed to become ready within ${timeout}s"
            echo "ðŸ” PostgreSQL logs:"
            docker logs $(docker ps -q --filter ancestor=postgres) || true
            exit 1
          fi

      - name: Setup test environment
        run: |
          cp .env.test.example .env.test
          echo "DATABASE_URL=postgresql://test:test@localhost:5432/vonkfi_test" >> .env.test
          echo "REDIS_URL=redis://localhost:6379" >> .env.test
          echo "NODE_ENV=test" >> .env.test

      - name: Run database migrations
        run: npm run db:migrate
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/vonkfi_test

      - name: Run unit tests with coverage (parallel)
        run: |
          set -e
          mkdir -p test-results
          
          # Function for retry logic
          retry_test() {
            local cmd="$1"
            local max_attempts=3
            local attempt=1
            
            while [ $attempt -le $max_attempts ]; do
              echo "Test attempt $attempt/$max_attempts"
              if eval "$cmd"; then
                echo "âœ… Tests passed on attempt $attempt"
                return 0
              else
                echo "âŒ Tests failed on attempt $attempt"
                if [ $attempt -eq $max_attempts ]; then
                  echo "ðŸ’¥ All test attempts failed"
                  return 1
                fi
                echo "â³ Waiting 10 seconds before retry..."
                sleep 10
                attempt=$((attempt + 1))
              fi
            done
          }
          
          case "${{ matrix.test-group }}" in
            core)
              retry_test "npx vitest run test/business-logic.test.ts test/calculation-features.test.ts test/error-handling.test.ts --coverage --reporter=json --outputFile=./test-results/unit-core-results.json"
              ;;
            api)
              retry_test "npx vitest run test/api.test.ts test/*api*.test.ts --coverage --reporter=json --outputFile=./test-results/unit-api-results.json"
              ;;
            frontend)
              retry_test "npx vitest run test/frontend-*.test.tsx test/ui-*.test.ts --coverage --reporter=json --outputFile=./test-results/unit-frontend-results.json"
              ;;
            services)
              retry_test "npx vitest run test/services/ --coverage --reporter=json --outputFile=./test-results/unit-services-results.json"
              ;;
          esac
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/vonkfi_test
          CI: true
          VITEST_MIN_THREADS: ${{ env.VITEST_MIN_THREADS }}
          VITEST_MAX_THREADS: ${{ env.VITEST_MAX_THREADS }}
          # Enhanced performance configuration
          NODE_OPTIONS: "--max-old-space-size=4096 --max-semi-space-size=128"
          # Test execution optimization
          VITEST_CI_PARALLEL: true
          VITEST_POOL: threads
          VITEST_POOL_SIZE: ${{ env.VITEST_MAX_THREADS }}
          # Vite optimization for tests
          VITE_NODE_CACHE: true
          VITE_CACHE_DIR: .vite
          # Test group specific optimization
          TEST_GROUP: ${{ matrix.test-group }}
          TEST_ISOLATION_ENABLED: true
          # Performance monitoring
          MEASURE_PERFORMANCE: true

      - name: Check coverage thresholds
        run: |
          npm run test:coverage:check

      - name: Upload coverage reports
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage/lcov.info
          flags: unittests
          name: codecov-umbrella

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results-${{ matrix.test-group }}
          path: |
            coverage/
            test-results/
            test-results.xml

  # Job 3: Integration Tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [config-validation, unit-tests]
    if: needs.config-validation.outputs.config_valid == 'true' && (needs.config-validation.outputs.test_level == 'all' || needs.config-validation.outputs.test_level == 'integration')
    
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}-alpine
        env:
          POSTGRES_DB: vonkfi_test
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:${{ env.REDIS_VERSION }}-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Setup integration test environment
        run: |
          cp .env.integration.example .env.integration
          echo "DATABASE_URL=postgresql://test:test@localhost:5432/vonkfi_test" >> .env.integration

      - name: Run database migrations
        run: npm run db:migrate
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/vonkfi_test

      - name: Seed test data
        run: npm run db:seed:test
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/vonkfi_test

      - name: Run integration tests
        run: npm run test:integration
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/vonkfi_test

      - name: Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: |
            integration-test-results.xml
            logs/

  # Job 4: End-to-End Tests
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [config-validation, integration-tests]
    if: needs.config-validation.outputs.config_valid == 'true' && (needs.config-validation.outputs.test_level == 'all' || needs.config-validation.outputs.test_level == 'e2e')
    
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}-alpine
        env:
          POSTGRES_DB: vonkfi_test
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright
        run: npx playwright install --with-deps

      - name: Build application
        run: npm run build

      - name: Setup E2E test environment
        run: |
          cp .env.e2e.example .env.e2e
          echo "DATABASE_URL=postgresql://test:test@localhost:5432/vonkfi_test" >> .env.e2e

      - name: Run database migrations
        run: npm run db:migrate
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/vonkfi_test

      - name: Seed E2E test data
        run: npm run db:seed:e2e
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/vonkfi_test

      - name: Start application
        run: |
          npm start &
          npx wait-on http://localhost:3000
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/vonkfi_test

      - name: Run E2E tests
        run: npm run test:e2e

      - name: Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results
          path: |
            test-results/
            playwright-report/

  # Job 5: Performance Tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: integration-tests
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}-alpine
        env:
          POSTGRES_DB: vonkfi_test
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Setup performance test environment
        run: |
          cp .env.performance.example .env.performance
          echo "DATABASE_URL=postgresql://test:test@localhost:5432/vonkfi_test" >> .env.performance

      - name: Run database migrations
        run: npm run db:migrate
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/vonkfi_test

      - name: Seed performance test data
        run: npm run db:seed:performance
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/vonkfi_test

      - name: Start application
        run: |
          npm start &
          npx wait-on http://localhost:3000
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/vonkfi_test

      - name: Run performance tests
        run: npm run test:performance

      - name: Upload performance test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-test-results
          path: |
            performance-results/
            artillery-reports/

  # Job 6: Build & Security Validation
  build-and-validate:
    name: Build & Security Validation
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Type checking
        run: npm run check

      - name: Build application
        run: npm run build

      - name: Run security linting
        run: |
          npx eslint . --ext .ts,.tsx,.js,.jsx \
            --config ./ci/eslint-security.config.js

      - name: Check for secrets in code
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: main
          head: HEAD

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            dist/
            build/

  # Job 7: Database Migration Tests
  migration-tests:
    name: Database Migration Tests
    runs-on: ubuntu-latest
    needs: security-scan
    
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}-alpine
        env:
          POSTGRES_DB: vonkfi_test
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Test database migrations
        run: npm run test:migrations
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/vonkfi_test

      - name: Test migration rollbacks
        run: npm run test:migrations:rollback
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/vonkfi_test

      - name: Upload migration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: migration-test-results
          path: |
            migration-test-results.json
            schema-validation-results.json

  # Job 8: Deployment Readiness Check
  deployment-readiness:
    name: Deployment Readiness Check
    runs-on: ubuntu-latest
    needs: [build-and-validate, e2e-tests, migration-tests]
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        continue-on-error: true

      - name: Validate deployment readiness
        run: |
          echo "ðŸ” Checking deployment readiness..."
          
          deployment_ready=true
          issues_found=()
          
          # Check if all required artifacts exist
          required_artifacts=(
            "build-artifacts"
            "unit-test-results"
            "integration-test-results"
            "e2e-test-results"
            "migration-test-results"
          )
          
          for artifact in "${required_artifacts[@]}"; do
            if [ ! -d "$artifact" ]; then
              echo "âŒ Missing required artifact: $artifact"
              issues_found+=("Missing artifact: $artifact")
              deployment_ready=false
            else
              echo "âœ… Found artifact: $artifact"
            fi
          done
          
          # Check for test failures in artifacts
          if [ -d "unit-test-results" ]; then
            for file in unit-test-results*/test-results/*.json; do
              if [ -f "$file" ]; then
                failures=$(jq -r '.numFailedTests // 0' "$file" 2>/dev/null || echo "0")
                if [ "$failures" -gt 0 ]; then
                  echo "âŒ Found $failures test failures in $file"
                  issues_found+=("Test failures: $failures in $(basename $file)")
                  deployment_ready=false
                fi
              fi
            done
          fi
          
          # Check build artifacts
          if [ -d "build-artifacts" ]; then
            if [ ! -d "build-artifacts/dist" ] && [ ! -d "build-artifacts/build" ]; then
              echo "âŒ No build output found in artifacts"
              issues_found+=("No build output found")
              deployment_ready=false
            fi
          fi
          
          # Generate readiness report
          if [ ${#issues_found[@]} -gt 0 ]; then
            echo "âŒ Deployment readiness check failed with issues:"
            printf '%s\n' "${issues_found[@]}"
            
            # Create failure report
            cat > deployment-readiness-report.json << EOF
          {
            "ready": false,
            "timestamp": "$(date -Iseconds)",
            "issues": $(printf '%s\n' "${issues_found[@]}" | jq -R . | jq -s .),
            "artifacts_checked": $(printf '%s\n' "${required_artifacts[@]}" | jq -R . | jq -s .)
          }
          EOF
            
            exit 1
          else
            echo "âœ… All deployment readiness checks passed"
            
            # Create success report
            cat > deployment-readiness-report.json << EOF
          {
            "ready": true,
            "timestamp": "$(date -Iseconds)",
            "artifacts_validated": $(printf '%s\n' "${required_artifacts[@]}" | jq -R . | jq -s .)
          }
          EOF
          fi

      - name: Create deployment summary
        run: |
          cat > deployment-summary.md << EOF
          # Deployment Summary
          
          ## Test Results
          - âœ… Security scan completed
          - âœ… Unit tests passed with coverage
          - âœ… Integration tests passed
          - âœ… E2E tests passed
          - âœ… Migration tests passed
          - âœ… Build validation passed
          
          ## Deployment Artifacts
          - Application build: Ready
          - Database migrations: Validated
          - Test coverage: Above threshold
          
          ## Next Steps
          - Ready for staging deployment
          - Performance tests completed (if main branch)
          - All quality gates passed
          EOF

      - name: Upload deployment summary
        uses: actions/upload-artifact@v4
        with:
          name: deployment-summary
          path: deployment-summary.md

  # Notification job
  notify:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [deployment-readiness]
    if: always()
    
    steps:
      - name: Notify success
        if: ${{ needs.deployment-readiness.result == 'success' }}
        run: |
          echo "ðŸŽ‰ All tests passed! Ready for deployment."
          
      - name: Notify failure
        if: ${{ needs.deployment-readiness.result == 'failure' }}
        run: |
          echo "âŒ Pipeline failed. Check the logs for details."
          exit 1