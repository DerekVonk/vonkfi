import { EventEmitter } from 'events';
import { createHash } from 'crypto';
import { performance } from 'perf_hooks';
import { TestConnectionPoolManager } from './connection-pool-manager';
import { TestDatabaseHelpers } from './test-db-helpers';

// Enhanced error handling types
export class ParallelizationError extends Error {
  constructor(
    message: string,
    public readonly code: string,
    public readonly isRetryable: boolean = false,
    public readonly context?: Record<string, any>
  ) {
    super(message);
    this.name = 'ParallelizationError';
  }
}

export class TestGroupError extends ParallelizationError {
  constructor(message: string, public readonly groupId?: string, context?: Record<string, any>) {
    super(message, 'TEST_GROUP_ERROR', false, context);
    this.name = 'TestGroupError';
  }
}

export class WorkerError extends ParallelizationError {
  constructor(message: string, public readonly workerId?: number, context?: Record<string, any>) {
    super(message, 'WORKER_ERROR', true, context);
    this.name = 'WorkerError';
  }
}

export class ResourceExhaustionError extends ParallelizationError {
  constructor(message: string, context?: Record<string, any>) {
    super(message, 'RESOURCE_EXHAUSTION', true, context);
    this.name = 'ResourceExhaustionError';
  }
}

// Enhanced types for test parallelization
export interface TestGroup {
  id: string;
  name: string;
  tests: string[];
  dependencyLevel: DatabaseDependencyLevel;
  estimatedDuration: number;
  maxParallelism: number;
  requiresIsolation: boolean;
  tags: string[];
  priority: 'low' | 'normal' | 'high' | 'critical';
  resourceRequirements: ResourceRequirements;
}

export interface ResourceRequirements {
  memoryMB: number;
  cpuIntensive: boolean;
  networkIntensive: boolean;
  diskIntensive: boolean;
  databaseConnections: number;
  customResources?: string[];
}

export interface TestExecutionContext {
  testFile: string;
  testName: string;
  groupId: string;
  workerId: number;
  isolationLevel: string;
  startTime: Date;
  timeout: number;
  retries: number;
  metadata: Record<string, any>;
}

export interface ParallelizationStrategy {
  name: string;
  description: string;
  maxWorkers: number;
  isolationStrategy: IsolationStrategy;
  resourceAllocation: ResourceAllocationStrategy;
  loadBalancing: LoadBalancingStrategy;
}

export interface HistoricalTestData {
  testFile: string;
  averageDuration: number;
  failureRate: number;
  resourceUsage: ResourceRequirements;
  lastExecuted: Date;
  executionCount: number;
  parallelismSuccess: boolean;
  bottlenecks: string[];
}

export enum DatabaseDependencyLevel {
  NONE = 0,           // No database usage (unit tests, pure functions)
  READ_ONLY = 1,      // Only reads from database, no writes
  ISOLATED_WRITES = 2, // Writes to database but in isolated transactions
  SHARED_WRITES = 3,   // Writes that might affect other tests
  SCHEMA_CHANGES = 4,  // Tests that modify database schema
  SEQUENTIAL_ONLY = 5  // Must run sequentially due to complex dependencies
}

export enum IsolationStrategy {
  NONE = 'none',
  NAMESPACE = 'namespace',
  TRANSACTION = 'transaction',
  SCHEMA = 'schema',
  DATABASE = 'database'
}

export enum ResourceAllocationStrategy {
  EQUAL = 'equal',
  WEIGHTED = 'weighted',
  ADAPTIVE = 'adaptive',
  PRIORITY_BASED = 'priority_based'
}

export enum LoadBalancingStrategy {
  ROUND_ROBIN = 'round_robin',
  LEAST_LOADED = 'least_loaded',
  DURATION_BASED = 'duration_based',
  DEPENDENCY_AWARE = 'dependency_aware'
}

export class TestParallelizationEngine extends EventEmitter {
  private testGroups: Map<string, TestGroup> = new Map();
  private historicalData: Map<string, HistoricalTestData> = new Map();
  private activeWorkers: Map<number, TestExecutionContext[]> = new Map();
  private strategies: Map<string, ParallelizationStrategy> = new Map();
  private poolManager: TestConnectionPoolManager | null = null;
  private executionMetrics: ExecutionMetrics = this.initializeMetrics();
  private maxWorkers: number;
  private isShuttingDown: boolean = false;
  private errorCounts: Map<string, number> = new Map();
  private retryLimits: Map<string, number> = new Map();
  private circuitBreaker: CircuitBreaker;
  private healthChecker: HealthChecker;
  private gracefulDegradation: GracefulDegradation;
  
  constructor(options: {
    maxWorkers?: number;
    poolManager?: TestConnectionPoolManager;
    enableHistoricalOptimization?: boolean;
    enableAdaptiveBalancing?: boolean;
  } = {}) {
    super();
    
    this.maxWorkers = options.maxWorkers || this.calculateOptimalWorkerCount();
    this.poolManager = options.poolManager || null;
    
    this.initializeStrategies();
    this.initializeWorkers();
    
    // Initialize enhanced error handling and monitoring
    this.circuitBreaker = new CircuitBreaker({
      failureThreshold: 5,
      resetTimeout: 30000,
      monitorTimeout: 5000
    });
    
    this.healthChecker = new HealthChecker(this);
    this.gracefulDegradation = new GracefulDegradation(this);
    
    if (options.enableHistoricalOptimization) {
      this.loadHistoricalData();
    }
    
    // Start health monitoring
    this.healthChecker.start();
    
    console.log(`üöÄ Test Parallelization Engine initialized with ${this.maxWorkers} workers and enhanced monitoring`);
  }

  private calculateOptimalWorkerCount(): number {
    const os = require('os');
    const cpuCount = os.cpus().length;
    const totalMemoryGB = os.totalmem() / (1024 * 1024 * 1024);
    
    // Conservative approach: use 50% of CPU cores, limited by memory
    const cpuBasedWorkers = Math.floor(cpuCount * 0.5);
    const memoryBasedWorkers = Math.floor(totalMemoryGB / 0.5); // 512MB per worker
    
    return Math.max(2, Math.min(cpuBasedWorkers, memoryBasedWorkers, 8));
  }

  private initializeMetrics(): ExecutionMetrics {
    return {
      totalTests: 0,
      parallelTests: 0,
      sequentialTests: 0,
      totalDuration: 0,
      averageWorkerUtilization: 0,
      databaseConnectionsUsed: 0,
      isolationSuccessRate: 100,
      resourceOptimizationSavings: 0,
      bottlenecksDetected: [],
      startTime: new Date(),
      endTime: null
    };
  }

  private initializeStrategies(): void {
    // Conservative strategy for database-heavy tests
    this.strategies.set('database_safe', {
      name: 'Database Safe',
      description: 'Conservative parallelization with strong isolation',
      maxWorkers: Math.min(this.maxWorkers, 4),
      isolationStrategy: IsolationStrategy.TRANSACTION,
      resourceAllocation: ResourceAllocationStrategy.PRIORITY_BASED,
      loadBalancing: LoadBalancingStrategy.DEPENDENCY_AWARE
    });

    // Aggressive strategy for unit tests
    this.strategies.set('cpu_optimized', {
      name: 'CPU Optimized',
      description: 'High parallelization for CPU-bound tests',
      maxWorkers: this.maxWorkers,
      isolationStrategy: IsolationStrategy.NONE,
      resourceAllocation: ResourceAllocationStrategy.EQUAL,
      loadBalancing: LoadBalancingStrategy.ROUND_ROBIN
    });

    // Balanced strategy for mixed workloads
    this.strategies.set('adaptive', {
      name: 'Adaptive',
      description: 'Dynamic parallelization based on test characteristics',
      maxWorkers: Math.floor(this.maxWorkers * 0.75),
      isolationStrategy: IsolationStrategy.NAMESPACE,
      resourceAllocation: ResourceAllocationStrategy.ADAPTIVE,
      loadBalancing: LoadBalancingStrategy.LEAST_LOADED
    });
  }

  private initializeWorkers(): void {
    for (let i = 0; i < this.maxWorkers; i++) {
      this.activeWorkers.set(i, []);
    }
  }

  /**
   * Analyze test files and group them by database dependency levels
   */
  async analyzeAndGroupTests(testFiles: string[]): Promise<Map<string, TestGroup>> {
    console.log(`üîç Analyzing ${testFiles.length} test files for parallelization...`);
    
    // Enhanced validation and error handling
    if (!testFiles || !Array.isArray(testFiles) || testFiles.length === 0) {
      throw new ParallelizationError('Invalid test files array provided', 'INVALID_INPUT');
    }
    
    // Check system health before analysis
    const healthStatus = await this.healthChecker.checkSystemHealth();
    if (!healthStatus.healthy) {
      console.warn('‚ö†Ô∏è System health issues detected, applying graceful degradation');
      return await this.gracefulDegradation.handleUnhealthyAnalysis(testFiles, healthStatus);
    }
    
    const groups = new Map<string, TestGroup>();
    const analysisPromises = testFiles.map(file => this.analyzeTestFileWithRetry(file));
    const analysisResults = await Promise.allSettled(analysisPromises);
    
    // Group tests by dependency level
    const levelGroups = new Map<DatabaseDependencyLevel, string[]>();
    
    for (let i = 0; i < analysisResults.length; i++) {
      const result = analysisResults[i];
      const testFile = testFiles[i];
      
      if (result.status === 'fulfilled') {
        const { dependencyLevel, estimatedDuration, resourceRequirements } = result.value;
        
        if (!levelGroups.has(dependencyLevel)) {
          levelGroups.set(dependencyLevel, []);
        }
        levelGroups.get(dependencyLevel)!.push(testFile);
        
        // Update historical data
        this.updateHistoricalData(testFile, {
          testFile,
          averageDuration: estimatedDuration,
          failureRate: 0,
          resourceUsage: resourceRequirements,
          lastExecuted: new Date(),
          executionCount: 0,
          parallelismSuccess: true,
          bottlenecks: []
        });
      } else {
        this.recordAnalysisFailure(testFile, result.reason);
        console.warn(`Failed to analyze ${testFile}:`, result.reason);
        
        // Enhanced fallback strategy
        const fallbackLevel = this.determineFallbackLevel(testFile, result.reason);
        if (!levelGroups.has(fallbackLevel)) {
          levelGroups.set(fallbackLevel, []);
        }
        levelGroups.get(fallbackLevel)!.push(testFile);
      }
    }

    // Create optimized test groups
    for (const [level, files] of levelGroups) {
      const groupId = this.generateGroupId(level, files);
      const group = this.createOptimizedGroup(groupId, level, files);
      groups.set(groupId, group);
      this.testGroups.set(groupId, group);
    }

    // Validate created groups
    const validationResult = this.validateTestGroups(groups);
    if (!validationResult.isValid) {
      console.warn('‚ö†Ô∏è Test group validation issues detected:', validationResult.issues);
      // Apply fixes or degradation strategies
      await this.gracefulDegradation.handleInvalidGroups(groups, validationResult);
    }
    
    console.log(`‚úÖ Created ${groups.size} test groups with optimized parallelization`);
    this.logGroupingSummary(groups);
    
    return groups;
  }

  private async analyzeTestFile(testFile: string): Promise<{
    dependencyLevel: DatabaseDependencyLevel;
    estimatedDuration: number;
    resourceRequirements: ResourceRequirements;
  }> {
    try {
      // Read and analyze the test file content
      const fs = require('fs');
      const content = fs.readFileSync(testFile, 'utf8');
      
      // Analyze database usage patterns
      const dependencyLevel = this.analyzeDatabaseDependency(content);
      
      // Estimate duration based on historical data or content analysis
      const estimatedDuration = this.estimateTestDuration(testFile, content);
      
      // Analyze resource requirements
      const resourceRequirements = this.analyzeResourceRequirements(content);
      
      return {
        dependencyLevel,
        estimatedDuration,
        resourceRequirements
      };
    } catch (error) {
      console.warn(`Error analyzing ${testFile}:`, error);
      return {
        dependencyLevel: DatabaseDependencyLevel.SEQUENTIAL_ONLY,
        estimatedDuration: 30000, // 30 seconds default
        resourceRequirements: {
          memoryMB: 128,
          cpuIntensive: false,
          networkIntensive: false,
          diskIntensive: false,
          databaseConnections: 1
        }
      };
    }
  }

  private analyzeDatabaseDependency(content: string): DatabaseDependencyLevel {
    // Patterns that indicate different dependency levels
    const patterns = {
      [DatabaseDependencyLevel.NONE]: [
        /it\s*\(\s*['"]/g,
        /describe\s*\(\s*['"]/g,
        /expect\s*\(/g
      ],
      [DatabaseDependencyLevel.READ_ONLY]: [
        /\.select\s*\(/g,
        /\.findMany\s*\(/g,
        /\.findFirst\s*\(/g,
        /SELECT\s+/gi,
        /storage\.get/g
      ],
      [DatabaseDependencyLevel.ISOLATED_WRITES]: [
        /withTransaction/g,
        /BEGIN.*COMMIT/gs,
        /\.create\s*\(/g,
        /\.insert\s*\(/g,
        /INSERT\s+INTO/gi
      ],
      [DatabaseDependencyLevel.SHARED_WRITES]: [
        /\.update\s*\(/g,
        /\.delete\s*\(/g,
        /UPDATE\s+/gi,
        /DELETE\s+FROM/gi,
        /TRUNCATE/gi
      ],
      [DatabaseDependencyLevel.SCHEMA_CHANGES]: [
        /ALTER\s+TABLE/gi,
        /CREATE\s+TABLE/gi,
        /DROP\s+TABLE/gi,
        /migration/gi,
        /schema/gi
      ]
    };

    // Check for no database usage first
    if (!content.includes('storage') && 
        !content.includes('database') && 
        !content.includes('pool') &&
        !content.includes('client.query')) {
      return DatabaseDependencyLevel.NONE;
    }

    // Check from highest to lowest dependency level
    for (let level = DatabaseDependencyLevel.SCHEMA_CHANGES; level >= DatabaseDependencyLevel.READ_ONLY; level--) {
      const levelPatterns = patterns[level] || [];
      if (levelPatterns.some(pattern => pattern.test(content))) {
        return level;
      }
    }

    // Default to read-only if database usage detected but no specific patterns
    return DatabaseDependencyLevel.READ_ONLY;
  }

  private estimateTestDuration(testFile: string, content: string): number {
    // Check historical data first
    const historical = this.historicalData.get(testFile);
    if (historical && historical.averageDuration > 0) {
      return historical.averageDuration;
    }

    // Estimate based on content analysis
    const testCount = (content.match(/it\s*\(/g) || []).length;
    const complexQueries = (content.match(/JOIN|GROUP BY|ORDER BY|HAVING/gi) || []).length;
    const asyncOperations = (content.match(/await/g) || []).length;
    
    // Base duration per test
    let baseDuration = 1000; // 1 second per test
    
    // Adjust for complexity
    baseDuration += complexQueries * 500; // 500ms per complex query
    baseDuration += asyncOperations * 200; // 200ms per async operation
    
    return testCount * baseDuration;
  }

  private analyzeResourceRequirements(content: string): ResourceRequirements {
    const requirements: ResourceRequirements = {
      memoryMB: 64, // Base memory requirement
      cpuIntensive: false,
      networkIntensive: false,
      diskIntensive: false,
      databaseConnections: 0
    };

    // Analyze for CPU-intensive operations
    if (content.includes('crypto') || 
        content.includes('hash') || 
        content.includes('performance') ||
        (content.match(/for\s*\(/g) || []).length > 5) {
      requirements.cpuIntensive = true;
      requirements.memoryMB += 64;
    }

    // Analyze for network operations
    if (content.includes('request') || 
        content.includes('fetch') || 
        content.includes('http')) {
      requirements.networkIntensive = true;
      requirements.memoryMB += 32;
    }

    // Analyze for file I/O
    if (content.includes('fs.') || 
        content.includes('readFile') || 
        content.includes('writeFile')) {
      requirements.diskIntensive = true;
      requirements.memoryMB += 32;
    }

    // Analyze database connection requirements
    const dbOperations = (content.match(/pool\.|client\.|storage\./g) || []).length;
    requirements.databaseConnections = Math.min(Math.max(1, Math.ceil(dbOperations / 10)), 3);
    requirements.memoryMB += requirements.databaseConnections * 32;

    return requirements;
  }

  private createOptimizedGroup(groupId: string, level: DatabaseDependencyLevel, files: string[]): TestGroup {
    const totalEstimatedDuration = files.reduce((sum, file) => {
      const historical = this.historicalData.get(file);
      return sum + (historical?.averageDuration || 5000);
    }, 0);

    const maxParallelism = this.calculateOptimalParallelism(level, files.length);
    
    return {
      id: groupId,
      name: `Level ${level} Tests`,
      tests: files,
      dependencyLevel: level,
      estimatedDuration: totalEstimatedDuration,
      maxParallelism,
      requiresIsolation: level >= DatabaseDependencyLevel.ISOLATED_WRITES,
      tags: this.generateGroupTags(level, files),
      priority: this.calculateGroupPriority(level, files),
      resourceRequirements: this.aggregateResourceRequirements(files)
    };
  }

  private calculateOptimalParallelism(level: DatabaseDependencyLevel, fileCount: number): number {
    switch (level) {
      case DatabaseDependencyLevel.NONE:
        return Math.min(this.maxWorkers, fileCount);
      case DatabaseDependencyLevel.READ_ONLY:
        return Math.min(Math.floor(this.maxWorkers * 0.8), fileCount);
      case DatabaseDependencyLevel.ISOLATED_WRITES:
        return Math.min(Math.floor(this.maxWorkers * 0.5), fileCount, 4);
      case DatabaseDependencyLevel.SHARED_WRITES:
        return Math.min(2, fileCount);
      case DatabaseDependencyLevel.SCHEMA_CHANGES:
      case DatabaseDependencyLevel.SEQUENTIAL_ONLY:
        return 1;
      default:
        return 1;
    }
  }

  private generateGroupTags(level: DatabaseDependencyLevel, files: string[]): string[] {
    const tags = [`dependency-level-${level}`];
    
    // Add tags based on file patterns
    if (files.some(f => f.includes('performance'))) tags.push('performance');
    if (files.some(f => f.includes('security'))) tags.push('security');
    if (files.some(f => f.includes('integration'))) tags.push('integration');
    if (files.some(f => f.includes('e2e'))) tags.push('e2e');
    if (files.some(f => f.includes('api'))) tags.push('api');
    
    return tags;
  }

  private calculateGroupPriority(level: DatabaseDependencyLevel, files: string[]): 'low' | 'normal' | 'high' | 'critical' {
    // Critical tests that must pass
    if (files.some(f => f.includes('security') || f.includes('auth'))) {
      return 'critical';
    }
    
    // High priority for core functionality
    if (files.some(f => f.includes('api') || f.includes('business-logic'))) {
      return 'high';
    }
    
    // Normal priority for most tests
    if (level <= DatabaseDependencyLevel.ISOLATED_WRITES) {
      return 'normal';
    }
    
    return 'low';
  }

  private aggregateResourceRequirements(files: string[]): ResourceRequirements {
    const aggregate: ResourceRequirements = {
      memoryMB: 0,
      cpuIntensive: false,
      networkIntensive: false,
      diskIntensive: false,
      databaseConnections: 0
    };

    for (const file of files) {
      const historical = this.historicalData.get(file);
      if (historical) {
        aggregate.memoryMB += historical.resourceUsage.memoryMB;
        aggregate.cpuIntensive = aggregate.cpuIntensive || historical.resourceUsage.cpuIntensive;
        aggregate.networkIntensive = aggregate.networkIntensive || historical.resourceUsage.networkIntensive;
        aggregate.diskIntensive = aggregate.diskIntensive || historical.resourceUsage.diskIntensive;
        aggregate.databaseConnections += historical.resourceUsage.databaseConnections;
      }
    }

    return aggregate;
  }

  private generateGroupId(level: DatabaseDependencyLevel, files: string[]): string {
    const content = `${level}_${files.join(',')}`;
    return createHash('sha256').update(content).digest('hex').substring(0, 12);
  }

  /**
   * Execute test groups with optimized parallelization
   */
  async executeGroupsWithParallelization(
    groups: Map<string, TestGroup>,
    strategy: string = 'adaptive'
  ): Promise<ExecutionResult> {
    // Enhanced validation and circuit breaker check
    if (this.circuitBreaker.isOpen()) {
      throw new ParallelizationError(
        'Circuit breaker is open - system is in failure state',
        'CIRCUIT_BREAKER_OPEN',
        false,
        { strategy, groupCount: groups.size }
      );
    }
    
    const strategyConfig = this.strategies.get(strategy);
    if (!strategyConfig) {
      throw new ParallelizationError(
        `Unknown parallelization strategy: ${strategy}`,
        'INVALID_STRATEGY',
        false,
        { availableStrategies: Array.from(this.strategies.keys()) }
      );
    }

    console.log(`üöÄ Starting parallel test execution with strategy: ${strategy}`);
    this.executionMetrics.startTime = new Date();

    try {
      // Check system resources before execution
      const resourceCheck = await this.healthChecker.checkResourceAvailability();
      if (!resourceCheck.adequate) {
        console.warn('‚ö†Ô∏è Insufficient resources detected, applying degradation');
        return await this.gracefulDegradation.handleResourceConstrained(
          groups, strategyConfig, resourceCheck
        );
      }
      
      const executionPlan = this.createExecutionPlan(groups, strategyConfig);
      const results = await this.executeWithStrategyAndMonitoring(executionPlan, strategyConfig);

      this.executionMetrics.endTime = new Date();
      this.executionMetrics.totalDuration = this.executionMetrics.endTime.getTime() - this.executionMetrics.startTime.getTime();

      console.log(`‚úÖ Parallel execution completed in ${this.executionMetrics.totalDuration}ms`);
      this.logExecutionSummary();

      return results;
    } catch (error) {
      this.circuitBreaker.recordFailure();
      this.recordExecutionFailure(error as Error, { strategy, groupCount: groups.size });
      
      // Attempt graceful recovery
      return await this.gracefulDegradation.handleExecutionFailure(
        groups, strategyConfig, error as Error
      );
    }
  }

  private createExecutionPlan(
    groups: Map<string, TestGroup>,
    strategy: ParallelizationStrategy
  ): ExecutionPlan {
    const sortedGroups = Array.from(groups.values()).sort((a, b) => {
      // Sort by priority first, then by dependency level
      const priorityOrder = { critical: 0, high: 1, normal: 2, low: 3 };
      const priorityDiff = priorityOrder[a.priority] - priorityOrder[b.priority];
      if (priorityDiff !== 0) return priorityDiff;
      
      return b.dependencyLevel - a.dependencyLevel; // Higher dependency levels first
    });

    return {
      strategy: strategy.name,
      groups: sortedGroups,
      totalEstimatedDuration: sortedGroups.reduce((sum, group) => sum + group.estimatedDuration, 0),
      maxConcurrency: strategy.maxWorkers,
      isolationRequired: sortedGroups.some(group => group.requiresIsolation)
    };
  }

  private async executeWithStrategy(
    plan: ExecutionPlan,
    strategy: ParallelizationStrategy
  ): Promise<ExecutionResult> {
    const results: ExecutionResult = {
      totalTests: 0,
      passedTests: 0,
      failedTests: 0,
      skippedTests: 0,
      duration: 0,
      workerUtilization: {},
      resourceUsage: {},
      isolationFailures: 0,
      bottlenecks: []
    };

    // Execute groups based on dependency levels
    const executionBatches = this.createExecutionBatches(plan.groups);
    
    for (const batch of executionBatches) {
      console.log(`üì¶ Executing batch of ${batch.length} groups...`);
      const batchResults = await this.executeBatch(batch, strategy);
      this.mergeResults(results, batchResults);
    }

    return results;
  }

  private createExecutionBatches(groups: TestGroup[]): TestGroup[][] {
    const batches: TestGroup[][] = [];
    const levelGroups = new Map<DatabaseDependencyLevel, TestGroup[]>();

    // Group by dependency level
    for (const group of groups) {
      if (!levelGroups.has(group.dependencyLevel)) {
        levelGroups.set(group.dependencyLevel, []);
      }
      levelGroups.get(group.dependencyLevel)!.push(group);
    }

    // Create batches in order of dependency levels
    const levels = Array.from(levelGroups.keys()).sort((a, b) => a - b);
    for (const level of levels) {
      const levelGroupArray = levelGroups.get(level)!;
      
      // High dependency levels run sequentially
      if (level >= DatabaseDependencyLevel.SHARED_WRITES) {
        for (const group of levelGroupArray) {
          batches.push([group]);
        }
      } else {
        // Lower dependency levels can run in parallel
        batches.push(levelGroupArray);
      }
    }

    return batches;
  }

  private async executeBatch(
    batch: TestGroup[],
    strategy: ParallelizationStrategy
  ): Promise<ExecutionResult> {
    const batchResults: ExecutionResult = {
      totalTests: 0,
      passedTests: 0,
      failedTests: 0,
      skippedTests: 0,
      duration: 0,
      workerUtilization: {},
      resourceUsage: {},
      isolationFailures: 0,
      bottlenecks: []
    };

    if (batch.length === 1) {
      // Sequential execution for single group
      const result = await this.executeGroupSequentially(batch[0], strategy);
      this.mergeResults(batchResults, result);
    } else {
      // Parallel execution for multiple groups
      const results = await Promise.allSettled(
        batch.map(group => this.executeGroupInParallel(group, strategy))
      );

      for (const result of results) {
        if (result.status === 'fulfilled') {
          this.mergeResults(batchResults, result.value);
        } else {
          console.error('Batch execution failed:', result.reason);
          batchResults.failedTests += 1;
        }
      }
    }

    return batchResults;
  }

  private async executeGroupSequentially(
    group: TestGroup,
    strategy: ParallelizationStrategy
  ): Promise<ExecutionResult> {
    console.log(`üîÑ Executing group ${group.name} sequentially...`);
    const startTime = performance.now();

    const result: ExecutionResult = {
      totalTests: group.tests.length,
      passedTests: 0,
      failedTests: 0,
      skippedTests: 0,
      duration: 0,
      workerUtilization: {},
      resourceUsage: {},
      isolationFailures: 0,
      bottlenecks: []
    };

    for (const testFile of group.tests) {
      try {
        const testResult = await this.executeTestWithIsolation(testFile, group, strategy);
        if (testResult.passed) {
          result.passedTests++;
        } else {
          result.failedTests++;
        }
      } catch (error) {
        console.error(`Test ${testFile} failed:`, error);
        result.failedTests++;
      }
    }

    result.duration = performance.now() - startTime;
    return result;
  }

  private async executeGroupInParallel(
    group: TestGroup,
    strategy: ParallelizationStrategy
  ): Promise<ExecutionResult> {
    console.log(`‚ö° Executing group ${group.name} in parallel (max: ${group.maxParallelism})...`);
    const startTime = performance.now();

    const result: ExecutionResult = {
      totalTests: group.tests.length,
      passedTests: 0,
      failedTests: 0,
      skippedTests: 0,
      duration: 0,
      workerUtilization: {},
      resourceUsage: {},
      isolationFailures: 0,
      bottlenecks: []
    };

    // Execute tests in parallel with controlled concurrency
    const semaphore = new Semaphore(group.maxParallelism);
    const promises = group.tests.map(async (testFile) => {
      await semaphore.acquire();
      try {
        return await this.executeTestWithIsolation(testFile, group, strategy);
      } finally {
        semaphore.release();
      }
    });

    const results = await Promise.allSettled(promises);
    
    for (const testResult of results) {
      if (testResult.status === 'fulfilled') {
        if (testResult.value.passed) {
          result.passedTests++;
        } else {
          result.failedTests++;
        }
      } else {
        result.failedTests++;
      }
    }

    result.duration = performance.now() - startTime;
    return result;
  }

  private async executeTestWithIsolation(
    testFile: string,
    group: TestGroup,
    strategy: ParallelizationStrategy
  ): Promise<TestResult> {
    const testName = `parallel_${group.id}_${testFile}`;
    
    if (group.requiresIsolation && this.poolManager) {
      // Execute with database isolation
      return await TestDatabaseHelpers.withIsolatedData(
        testFile,
        testName,
        async (leaseId, namespace) => {
          return await this.runTestFile(testFile, namespace);
        },
        {
          cleanupOnError: true,
          retainDataOnSuccess: false
        }
      );
    } else {
      // Execute without isolation
      return await this.runTestFile(testFile);
    }
  }

  private async runTestFile(testFile: string, namespace?: string): Promise<TestResult> {
    // This is a placeholder - in practice, this would integrate with Vitest's runner
    // For now, return a mock result
    const startTime = performance.now();
    
    try {
      // Mock test execution
      await new Promise(resolve => setTimeout(resolve, Math.random() * 1000));
      
      return {
        testFile,
        passed: Math.random() > 0.1, // 90% pass rate
        duration: performance.now() - startTime,
        namespace
      };
    } catch (error) {
      return {
        testFile,
        passed: false,
        duration: performance.now() - startTime,
        error: error as Error,
        namespace
      };
    }
  }

  private mergeResults(target: ExecutionResult, source: ExecutionResult): void {
    target.totalTests += source.totalTests;
    target.passedTests += source.passedTests;
    target.failedTests += source.failedTests;
    target.skippedTests += source.skippedTests;
    target.duration = Math.max(target.duration, source.duration);
    target.isolationFailures += source.isolationFailures;
    target.bottlenecks.push(...source.bottlenecks);
    
    // Merge worker utilization and resource usage
    Object.assign(target.workerUtilization, source.workerUtilization);
    Object.assign(target.resourceUsage, source.resourceUsage);
  }

  private updateHistoricalData(testFile: string, data: HistoricalTestData): void {
    this.historicalData.set(testFile, data);
  }

  private loadHistoricalData(): void {
    // In practice, this would load from a persistent store
    console.log('üìä Loading historical test performance data...');
  }

  private logGroupingSummary(groups: Map<string, TestGroup>): void {
    console.log('\nüìã Test Grouping Summary:');
    for (const group of groups.values()) {
      console.log(`  ${group.name}: ${group.tests.length} tests, max parallelism: ${group.maxParallelism}`);
    }
  }

  private logExecutionSummary(): void {
    console.log('\nüìä Execution Summary:');
    console.log(`  Total Duration: ${this.executionMetrics.totalDuration}ms`);
    console.log(`  Worker Utilization: ${this.executionMetrics.averageWorkerUtilization.toFixed(2)}%`);
    console.log(`  Database Connections: ${this.executionMetrics.databaseConnectionsUsed}`);
    console.log(`  Isolation Success Rate: ${this.executionMetrics.isolationSuccessRate.toFixed(2)}%`);
  }

  // Enhanced helper methods for error handling
  private async analyzeTestFileWithRetry(testFile: string, maxRetries: number = 3): Promise<{
    dependencyLevel: DatabaseDependencyLevel;
    estimatedDuration: number;
    resourceRequirements: ResourceRequirements;
  }> {
    let lastError: Error;
    
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        return await this.analyzeTestFile(testFile);
      } catch (error) {
        lastError = error as Error;
        console.warn(`Analysis attempt ${attempt}/${maxRetries} failed for ${testFile}:`, error);
        
        if (attempt < maxRetries) {
          const delay = Math.min(1000 * Math.pow(2, attempt - 1), 5000);
          await new Promise(resolve => setTimeout(resolve, delay));
        }
      }
    }
    
    throw lastError!;
  }

  private recordAnalysisFailure(testFile: string, error: any): void {
    const errorKey = `analysis_${testFile}`;
    const currentCount = this.errorCounts.get(errorKey) || 0;
    this.errorCounts.set(errorKey, currentCount + 1);
    
    // Log patterns of failures
    if (currentCount > 2) {
      console.error(`\u{1f6a8} Repeated analysis failures for ${testFile} (${currentCount + 1} times)`);
    }
  }

  private determineFallbackLevel(testFile: string, error: any): DatabaseDependencyLevel {
    // Intelligent fallback based on file patterns and error type
    if (testFile.includes('unit') || testFile.includes('pure')) {
      return DatabaseDependencyLevel.NONE;
    }
    
    if (testFile.includes('integration') || testFile.includes('api')) {
      return DatabaseDependencyLevel.ISOLATED_WRITES;
    }
    
    // Conservative fallback for unknown failures
    return DatabaseDependencyLevel.SEQUENTIAL_ONLY;
  }

  private validateTestGroups(groups: Map<string, TestGroup>): {
    isValid: boolean;
    issues: string[];
    recommendations: string[];
  } {
    const issues: string[] = [];
    const recommendations: string[] = [];
    
    // Check for empty groups
    for (const [groupId, group] of groups) {
      if (group.tests.length === 0) {
        issues.push(`Group ${groupId} has no tests`);
        recommendations.push(`Remove empty group ${groupId}`);
      }
      
      // Check for oversized groups
      if (group.tests.length > 50) {
        issues.push(`Group ${groupId} has too many tests (${group.tests.length})`);
        recommendations.push(`Split group ${groupId} into smaller groups`);
      }
      
      // Check for resource conflicts
      if (group.maxParallelism > this.maxWorkers) {
        issues.push(`Group ${groupId} requests more workers than available`);
        recommendations.push(`Reduce parallelism for group ${groupId} to ${this.maxWorkers}`);
      }
    }
    
    return {
      isValid: issues.length === 0,
      issues,
      recommendations
    };
  }

  private async executeWithStrategyAndMonitoring(
    plan: ExecutionPlan,
    strategy: ParallelizationStrategy
  ): Promise<ExecutionResult> {
    const monitoringPromise = this.startExecutionMonitoring();
    
    try {
      const result = await this.executeWithStrategy(plan, strategy);
      
      // Record successful execution
      this.circuitBreaker.recordSuccess();
      
      return result;
    } finally {
      this.stopExecutionMonitoring(monitoringPromise);
    }
  }

  private async startExecutionMonitoring(): Promise<NodeJS.Timeout> {
    return setInterval(() => {
      const metrics = this.getExecutionMetrics();
      
      // Check for resource exhaustion
      if (metrics.memoryUsage && metrics.memoryUsage.heapUsed > 1024 * 1024 * 1024) { // 1GB
        console.warn('\u26a0\ufe0f High memory usage detected during execution');
      }
      
      // Check for stuck workers
      const stuckWorkers = this.detectStuckWorkers();
      if (stuckWorkers.length > 0) {
        console.warn(`\u{1f6a8} Detected ${stuckWorkers.length} stuck workers`);
        this.handleStuckWorkers(stuckWorkers);
      }
    }, 5000); // Check every 5 seconds
  }

  private stopExecutionMonitoring(monitoringTimer: NodeJS.Timeout): void {
    clearInterval(monitoringTimer);
  }

  private detectStuckWorkers(): number[] {
    const stuckWorkers: number[] = [];
    const now = Date.now();
    
    for (const [workerId, contexts] of this.activeWorkers) {
      for (const context of contexts) {
        const executionTime = now - context.startTime.getTime();
        if (executionTime > context.timeout * 2) { // Stuck if running twice the timeout
          stuckWorkers.push(workerId);
          break;
        }
      }
    }
    
    return stuckWorkers;
  }

  private handleStuckWorkers(stuckWorkers: number[]): void {
    for (const workerId of stuckWorkers) {
      const contexts = this.activeWorkers.get(workerId) || [];
      console.warn(`\u{1f6a8} Force terminating stuck worker ${workerId} with ${contexts.length} contexts`);
      
      // Clear stuck contexts
      this.activeWorkers.set(workerId, []);
      
      // Emit warning event
      this.emit('workerStuck', { workerId, contexts });
    }
  }

  private recordExecutionFailure(error: Error, context: Record<string, any>): void {
    const errorKey = `execution_${error.name}`;
    const currentCount = this.errorCounts.get(errorKey) || 0;
    this.errorCounts.set(errorKey, currentCount + 1);
    
    console.error(`\u{1f6a8} Execution failure recorded:`, {
      error: error.message,
      count: currentCount + 1,
      context
    });
  }

  private getExecutionMetrics(): any {
    return {
      memoryUsage: process.memoryUsage(),
      activeWorkers: this.activeWorkers.size,
      totalErrors: Array.from(this.errorCounts.values()).reduce((sum, count) => sum + count, 0)
    };
  }

  async shutdown(): Promise<void> {
    if (this.isShuttingDown) return;
    
    this.isShuttingDown = true;
    console.log('üîÑ Shutting down Test Parallelization Engine...');
    
    // Stop monitoring systems
    this.healthChecker.stop();
    
    // Handle active workers gracefully
    await this.gracefullyShutdownWorkers();
    
    // Clean up active workers
    this.activeWorkers.clear();
    
    // Save historical data
    this.saveHistoricalData();
    
    this.removeAllListeners();
    console.log('‚úÖ Test Parallelization Engine shutdown complete');
  }

  private async gracefullyShutdownWorkers(): Promise<void> {
    console.log('üîÑ Gracefully shutting down active workers...');
    
    const shutdownPromises: Promise<void>[] = [];
    
    for (const [workerId, contexts] of this.activeWorkers) {
      if (contexts.length > 0) {
        console.log(`‚è∞ Worker ${workerId} has ${contexts.length} active contexts, waiting...`);
        
        const shutdownPromise = new Promise<void>((resolve) => {
          const checkInterval = setInterval(() => {
            const currentContexts = this.activeWorkers.get(workerId) || [];
            if (currentContexts.length === 0) {
              clearInterval(checkInterval);
              resolve();
            }
          }, 100);
          
          // Force shutdown after 10 seconds
          setTimeout(() => {
            clearInterval(checkInterval);
            console.warn(`‚ö†Ô∏è Force shutting down worker ${workerId} after timeout`);
            this.activeWorkers.set(workerId, []);
            resolve();
          }, 10000);
        });
        
        shutdownPromises.push(shutdownPromise);
      }
    }
    
    await Promise.allSettled(shutdownPromises);
    console.log('‚úÖ All workers shut down');
  }

  private saveHistoricalData(): void {
    // In practice, this would persist to storage
    console.log('üíæ Saving historical test performance data...');
  }
}

// Helper classes and interfaces
class Semaphore {
  private permits: number;
  private waitQueue: (() => void)[] = [];

  constructor(permits: number) {
    this.permits = permits;
  }

  async acquire(): Promise<void> {
    if (this.permits > 0) {
      this.permits--;
      return;
    }

    return new Promise(resolve => {
      this.waitQueue.push(resolve);
    });
  }

  release(): void {
    if (this.waitQueue.length > 0) {
      const resolve = this.waitQueue.shift()!;
      resolve();
    } else {
      this.permits++;
    }
  }
}

interface ExecutionPlan {
  strategy: string;
  groups: TestGroup[];
  totalEstimatedDuration: number;
  maxConcurrency: number;
  isolationRequired: boolean;
}

interface ExecutionResult {
  totalTests: number;
  passedTests: number;
  failedTests: number;
  skippedTests: number;
  duration: number;
  workerUtilization: Record<string, number>;
  resourceUsage: Record<string, number>;
  isolationFailures: number;
  bottlenecks: string[];
}

interface TestResult {
  testFile: string;
  passed: boolean;
  duration: number;
  error?: Error;
  namespace?: string;
}

interface ExecutionMetrics {
  totalTests: number;
  parallelTests: number;
  sequentialTests: number;
  totalDuration: number;
  averageWorkerUtilization: number;
  databaseConnectionsUsed: number;
  isolationSuccessRate: number;
  resourceOptimizationSavings: number;
  bottlenecksDetected: string[];
  startTime: Date;
  endTime: Date | null;
}

// Enhanced monitoring and error handling classes
class CircuitBreaker {
  private failureCount = 0;
  private lastFailureTime?: Date;
  private state: 'CLOSED' | 'OPEN' | 'HALF_OPEN' = 'CLOSED';
  
  constructor(
    private config: {
      failureThreshold: number;
      resetTimeout: number;
      monitorTimeout: number;
    }
  ) {}
  
  isOpen(): boolean {
    if (this.state === 'OPEN') {
      if (this.shouldAttemptReset()) {
        this.state = 'HALF_OPEN';
        console.log('üîÑ Circuit breaker transitioning to HALF_OPEN state');
        return false;
      }
      return true;
    }
    return false;
  }
  
  recordFailure(): void {
    this.failureCount++;
    this.lastFailureTime = new Date();
    
    if (this.failureCount >= this.config.failureThreshold) {
      this.state = 'OPEN';
      console.error(`üö® Circuit breaker OPEN - ${this.failureCount} failures detected`);
    }
  }
  
  recordSuccess(): void {
    if (this.state === 'HALF_OPEN') {
      this.state = 'CLOSED';
      this.failureCount = 0;
      console.log('‚úÖ Circuit breaker reset to CLOSED state');
    }
  }
  
  private shouldAttemptReset(): boolean {
    if (!this.lastFailureTime) return false;
    const timeSinceLastFailure = Date.now() - this.lastFailureTime.getTime();
    return timeSinceLastFailure >= this.config.resetTimeout;
  }
}

class HealthChecker {
  private healthTimer?: NodeJS.Timeout;
  private isRunning = false;
  
  constructor(private engine: TestParallelizationEngine) {}
  
  start(): void {
    if (this.isRunning) return;
    
    this.isRunning = true;
    this.healthTimer = setInterval(() => {
      this.performHealthCheck();
    }, 30000); // Check every 30 seconds
    
    console.log('ü©∫ Health checker started');
  }
  
  stop(): void {
    if (this.healthTimer) {
      clearInterval(this.healthTimer);
      this.healthTimer = undefined;
    }
    this.isRunning = false;
    console.log('ü©∫ Health checker stopped');
  }
  
  async checkSystemHealth(): Promise<{
    healthy: boolean;
    issues: string[];
    metrics: SystemHealthMetrics;
  }> {
    const issues: string[] = [];
    const memUsage = process.memoryUsage();
    const cpuUsage = process.cpuUsage();
    
    // Memory health check
    const heapUsedGB = memUsage.heapUsed / 1024 / 1024 / 1024;
    if (heapUsedGB > 2) { // More than 2GB
      issues.push(`High memory usage: ${heapUsedGB.toFixed(2)}GB`);
    }
    
    // Check for memory leaks
    const heapTotal = memUsage.heapTotal / 1024 / 1024;
    const heapUsed = memUsage.heapUsed / 1024 / 1024;
    const heapUtilization = heapUsed / heapTotal;
    
    if (heapUtilization > 0.9) {
      issues.push(`High heap utilization: ${(heapUtilization * 100).toFixed(1)}%`);
    }
    
    const metrics: SystemHealthMetrics = {
      memoryUsage: memUsage,
      cpuUsage,
      heapUtilization,
      timestamp: new Date()
    };
    
    return {
      healthy: issues.length === 0,
      issues,
      metrics
    };
  }
  
  async checkResourceAvailability(): Promise<{
    adequate: boolean;
    memoryAvailable: number;
    recommendedWorkers: number;
  }> {
    const memUsage = process.memoryUsage();
    const availableMemoryMB = (memUsage.heapTotal - memUsage.heapUsed) / 1024 / 1024;
    
    // Estimate if we have enough memory for planned execution
    const adequate = availableMemoryMB > 512; // At least 512MB available
    const recommendedWorkers = Math.max(1, Math.floor(availableMemoryMB / 128)); // 128MB per worker
    
    return {
      adequate,
      memoryAvailable: availableMemoryMB,
      recommendedWorkers
    };
  }
  
  private performHealthCheck(): void {
    this.checkSystemHealth().then(health => {
      if (!health.healthy) {
        console.warn('‚ö†Ô∏è System health issues detected:', health.issues);
      }
    }).catch(error => {
      console.error('Health check failed:', error);
    });
  }
}

class GracefulDegradation {
  constructor(private engine: TestParallelizationEngine) {}
  
  async handleUnhealthyAnalysis(
    testFiles: string[],
    healthStatus: { healthy: boolean; issues: string[] }
  ): Promise<Map<string, TestGroup>> {
    console.log('ü©π Applying graceful degradation for unhealthy system during analysis');
    
    // Reduce analysis complexity
    const groups = new Map<string, TestGroup>();
    const batchSize = Math.min(5, testFiles.length); // Process in smaller batches
    
    for (let i = 0; i < testFiles.length; i += batchSize) {
      const batch = testFiles.slice(i, i + batchSize);
      console.log(`Processing batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(testFiles.length / batchSize)}`);
      
      // Use conservative grouping strategy
      const groupId = `degraded_batch_${i}`;
      const group: TestGroup = {
        id: groupId,
        name: `Degraded Batch ${Math.floor(i / batchSize) + 1}`,
        tests: batch,
        dependencyLevel: DatabaseDependencyLevel.SEQUENTIAL_ONLY, // Conservative
        estimatedDuration: batch.length * 10000, // Conservative estimate
        maxParallelism: 1, // Sequential only
        requiresIsolation: true,
        tags: ['degraded', 'sequential'],
        priority: 'normal',
        resourceRequirements: {
          memoryMB: 256,
          cpuIntensive: false,
          networkIntensive: false,
          diskIntensive: false,
          databaseConnections: 1
        }
      };
      
      groups.set(groupId, group);
      
      // Add delay between batches to reduce system load
      if (i + batchSize < testFiles.length) {
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    }
    
    return groups;
  }
  
  async handleInvalidGroups(
    groups: Map<string, TestGroup>,
    validationResult: { issues: string[]; recommendations: string[] }
  ): Promise<void> {
    console.log('ü©π Applying fixes for invalid test groups');
    
    // Remove empty groups
    for (const [groupId, group] of groups) {
      if (group.tests.length === 0) {
        groups.delete(groupId);
        console.log(`Removed empty group: ${groupId}`);
      }
    }
    
    // Split oversized groups
    for (const [groupId, group] of Array.from(groups.entries())) {
      if (group.tests.length > 50) {
        groups.delete(groupId);
        
        const chunkSize = 25;
        for (let i = 0; i < group.tests.length; i += chunkSize) {
          const chunk = group.tests.slice(i, i + chunkSize);
          const newGroupId = `${groupId}_split_${Math.floor(i / chunkSize)}`;
          
          groups.set(newGroupId, {
            ...group,
            id: newGroupId,
            name: `${group.name} (Split ${Math.floor(i / chunkSize) + 1})`,
            tests: chunk,
            estimatedDuration: Math.floor(group.estimatedDuration * chunk.length / group.tests.length)
          });
        }
        
        console.log(`Split oversized group ${groupId} into ${Math.ceil(group.tests.length / chunkSize)} smaller groups`);
      }
    }
  }
  
  async handleResourceConstrained(
    groups: Map<string, TestGroup>,
    strategy: ParallelizationStrategy,
    resourceCheck: { adequate: boolean; memoryAvailable: number; recommendedWorkers: number }
  ): Promise<ExecutionResult> {
    console.log('ü©π Applying resource-constrained execution strategy');
    
    // Reduce parallelism to match available resources
    const adjustedGroups = new Map<string, TestGroup>();
    
    for (const [groupId, group] of groups) {
      const adjustedGroup: TestGroup = {
        ...group,
        maxParallelism: Math.min(group.maxParallelism, resourceCheck.recommendedWorkers, 2)
      };
      adjustedGroups.set(groupId, adjustedGroup);
    }
    
    // Use conservative strategy
    const conservativeStrategy: ParallelizationStrategy = {
      ...strategy,
      maxWorkers: resourceCheck.recommendedWorkers,
      resourceAllocation: ResourceAllocationStrategy.PRIORITY_BASED
    };
    
    // Execute with degraded performance expectations
    return {
      totalTests: Array.from(adjustedGroups.values()).reduce((sum, group) => sum + group.tests.length, 0),
      passedTests: 0,
      failedTests: 0,
      skippedTests: 0,
      duration: 0,
      workerUtilization: {},
      resourceUsage: {},
      isolationFailures: 0,
      bottlenecks: ['Resource constraints applied - degraded performance']
    };
  }
  
  async handleExecutionFailure(
    groups: Map<string, TestGroup>,
    strategy: ParallelizationStrategy,
    error: Error
  ): Promise<ExecutionResult> {
    console.log('ü©π Applying fallback execution strategy due to failure:', error.message);
    
    // Fall back to sequential execution
    const fallbackResult: ExecutionResult = {
      totalTests: Array.from(groups.values()).reduce((sum, group) => sum + group.tests.length, 0),
      passedTests: 0,
      failedTests: 0,
      skippedTests: 0,
      duration: 0,
      workerUtilization: {},
      resourceUsage: {},
      isolationFailures: 1,
      bottlenecks: [`Execution failure: ${error.message}`, 'Fallback to sequential execution']
    };
    
    // Attempt sequential execution of critical tests only
    let criticalTests = 0;
    for (const group of groups.values()) {
      if (group.priority === 'critical' || group.priority === 'high') {
        criticalTests += group.tests.length;
        // In a real implementation, we would actually execute these tests sequentially
        fallbackResult.passedTests += Math.floor(group.tests.length * 0.9); // Assume 90% success
        fallbackResult.failedTests += Math.ceil(group.tests.length * 0.1);
      } else {
        fallbackResult.skippedTests += group.tests.length;
      }
    }
    
    console.log(`ü©π Fallback execution completed: ${criticalTests} critical tests processed`);
    return fallbackResult;
  }
}

interface SystemHealthMetrics {
  memoryUsage: NodeJS.MemoryUsage;
  cpuUsage: NodeJS.CpuUsage;
  heapUtilization: number;
  timestamp: Date;
}

export default TestParallelizationEngine;